{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import regex as re\n",
    "import autocorrect\n",
    "from pandarallel import pandarallel\n",
    "import spacy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import random\n",
    "import numpy as np\n",
    "from multiprocessing import  Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'data/content_dataset.csv'\n",
    "data = pd.read_csv(path, encoding='utf-8')\n",
    "data_full = pd.read_csv(r'data/content_dataset_full.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl = autocorrect.Speller(lang='en')\n",
    "\n",
    "    \n",
    "def remove_xa0(text):\n",
    "    # Remove the \\xa0 symbol from the text, this appears due to some encoding error\n",
    "    return unicodedata.normalize(\"NFKD\",  text)\n",
    "\n",
    "\n",
    "def remove_symbols(text):\n",
    "    # remove anything that's not alphanumeric and whitespace\n",
    "    pattern = '[^\\w\\s]|-|_'\n",
    "    return re.sub(pattern, \"\", text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stemmer(text):\n",
    "    stem = SnowballStemmer(language='english')\n",
    "    stems = []\n",
    "    for word in text.split():\n",
    "        stems.append(stem.stem(word))\n",
    "    \n",
    "    return \" \".join(stems)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def preprocess(dataframe, sentences=1000, sample=True):\n",
    "    \n",
    "    if sample:\n",
    "        \n",
    "        df = dataframe.head(sentences).copy()\n",
    "    else:\n",
    "        df = dataframe.copy()\n",
    "    methods = {'remove \"\\\\xa0\"': remove_xa0,\n",
    "              'remove symbols': remove_symbols,\n",
    "              'stemming': stemmer}\n",
    "    \n",
    "    for method in methods.keys():\n",
    "#         print(f\"Performing method {method}\")\n",
    "        df.iloc[:, 0]= df.iloc[:, 0].apply(lambda x: methods[method](x))\n",
    "    \n",
    "#     pandarallel.initialize()\n",
    "    \n",
    "#     df.iloc[:, 0]= df.iloc[:, 0].parallel_apply(lemmatizer)\n",
    "#     df.iloc[:, 0]= df.iloc[:, 0].apply(lambda x: lemmatizer(x))\n",
    "#     for index in range(sentences):\n",
    "#         print(index)\n",
    "#         df.iloc[index, 0]= df.iloc[index, 0].apply(lambda x: lemmatizer(x), axis=1)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = preprocess(data_full, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"./data/processed_full.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
